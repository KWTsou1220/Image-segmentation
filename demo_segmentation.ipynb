{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from models import UNet\n",
    "from utils import increase_batch, mini_batch\n",
    "from utils import read_EM\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "x_train, t_train, x_test = read_EM(\"./Dataset/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unet = UNet(LR=1e-4, input_shape=[None, x_train.shape[1], x_train.shape[2], 1], \n",
    "            output_shape=[None, t_train.shape[1], t_train.shape[2], 1], )\n",
    "\n",
    "# Loss\n",
    "def loss(y, t):\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=t, logits=y)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss\n",
    "unet.optimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0    Loss: 0.486629517 Time: 28.78      \n",
      "Epoch: 1    Loss: 0.351954122 Time: 19.67      \n",
      "Epoch: 2    Loss: 0.311473751 Time: 19.77      \n",
      "Epoch: 3    Loss: 0.300134595 Time: 19.86      \n",
      "Epoch: 4    Loss: 0.294581190 Time: 19.85      \n",
      "Epoch: 5    Loss: 0.290307743 Time: 19.88      \n",
      "Epoch: 6    Loss: 0.304993431 Time: 19.96      \n",
      "Epoch: 7    Loss: 0.281674750 Time: 19.98      \n",
      "Epoch: 8    Loss: 0.281825716 Time: 19.98      \n",
      "Epoch: 9    Loss: 0.271816172 Time: 19.97      \n",
      "Epoch: 10   Loss: 0.260757534 Time: 19.99      \n",
      "Epoch: 11   Loss: 0.253999563 Time: 19.96      \n",
      "Epoch: 12   Loss: 0.251973872 Time: 19.98      \n",
      "Epoch: 13   Loss: 0.239099472 Time: 19.99      \n",
      "Epoch: 14   Loss: 0.240805492 Time: 19.99      \n",
      "Epoch: 15   Loss: 0.235163855 Time: 19.99      \n",
      "Epoch: 16   Loss: 0.230567812 Time: 19.99      \n",
      "Epoch: 17   Loss: 0.232469178 Time: 20.01      \n",
      "Epoch: 18   Loss: 0.226891549 Time: 19.98      \n",
      "Epoch: 19   Loss: 0.224884062 Time: 20.01      \n",
      "Epoch: 20   Loss: 0.220938953 Time: 20.01      \n",
      "Epoch: 21   Loss: 0.218388808 Time: 20.00      \n",
      "Epoch: 22   Loss: 0.215908568 Time: 20.03      \n",
      "Epoch: 23   Loss: 0.215925360 Time: 20.03      \n",
      "Epoch: 24   Loss: 0.218200236 Time: 20.03      \n",
      "Epoch: 25   Loss: 0.209353215 Time: 20.05      \n",
      "Epoch: 26   Loss: 0.207824102 Time: 20.05      \n",
      "Epoch: 27   Loss: 0.206919761 Time: 20.02      \n",
      "Epoch: 28   Loss: 0.205050696 Time: 20.01      \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-750c09d235bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0munet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         }\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0munet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Tsou\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Tsou\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Tsou\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mD:\\Tsou\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Tsou\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch = 30\n",
    "batch_size = increase_batch(start=1, bound=3, rate=1e-3)\n",
    "for ep in range(epoch):\n",
    "    count = 0\n",
    "    total_loss = 0\n",
    "    start = time.time()\n",
    "    for x, t in mini_batch(x_train, t_train, batch_generator=batch_size):\n",
    "        count += 1\n",
    "        feed_dict = {\n",
    "            unet.x: np.expand_dims(x, axis=3),\n",
    "            unet.t: np.expand_dims(t, axis=3),\n",
    "        }\n",
    "        loss, _ = sess.run([unet.loss, unet.training], feed_dict=feed_dict)\n",
    "        total_loss += loss\n",
    "    end = time.time()\n",
    "    print(\"Epoch: {:<4} Loss: {:<10.9f} Time: {:<10.2f} \".format(ep, total_loss/count, end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess, \"./Models/unet_small_without_1by1.ckpt\")\n",
    "print(\"Model saved in path: \" + save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#saver = tf.train.Saver()\n",
    "#saver.restore(sess, './Models/unet_small.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feed_dict = {\n",
    "    unet.x: np.expand_dims(x_test[0:1], axis=3),\n",
    "    #ae.t: np.expand_dims(t_test[0:1], axis=3),\n",
    "}\n",
    "\n",
    "y_test = sess.run(unet.y, feed_dict=feed_dict)\n",
    "y_test = np.squeeze(y_test)\n",
    "y_test = sess.run(tf.sigmoid(y_test))\n",
    "\n",
    "%matplotlib inline\n",
    "f, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].set_title(\"original\", size=25)\n",
    "ax[0].imshow(x_test[0], cmap=\"gray\")\n",
    "ax[1].set_title(\"segmented image\", size=25)\n",
    "ax[1].imshow(y_test, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feed_dict = {\n",
    "    unet.x: np.expand_dims(x_train[0:1], axis=3),\n",
    "    #ae.t: np.expand_dims(t_test[0:1], axis=3),\n",
    "}\n",
    "\n",
    "y_test = sess.run(unet.y, feed_dict=feed_dict)\n",
    "y_test = np.squeeze(y_test)\n",
    "y_test = sess.run(tf.sigmoid(y_test))\n",
    "\n",
    "%matplotlib inline\n",
    "f, ax = plt.subplots(1, 3, figsize=(20, 10))\n",
    "ax[0].set_title(\"original\", size=25)\n",
    "ax[0].imshow(x_train[0], cmap=\"gray\")\n",
    "ax[1].set_title(\"segmented image\", size=25)\n",
    "ax[1].imshow(y_test, cmap=\"gray\")\n",
    "ax[2].set_title('ground truth', size=25)\n",
    "ax[2].imshow(t_train[0], cmap=\"gray\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
